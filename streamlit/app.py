# streamlit/app.py
# streamlit/app.py
import streamlit as st
import os
from pathlib import Path
import shutil
# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –æ–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏
from rag_core import build_and_load_knowledge_base, create_rag_chain, _load_api_key_from_env, hybrid_search_with_rerank
import rag_core as rc

# --- –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="RAG-—á–∞—Ç —Å –≤–∞—à–∏–º–∏ PDF",
    page_icon="ü§ñ",
    layout="wide"
)

st.title("ü§ñ RAG-—á–∞—Ç —Å –≤–∞—à–∏–º–∏ PDF-–¥–æ–∫—É–º–µ–Ω—Ç–∞–º–∏")
st.markdown("""
–≠—Ç–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –ø–æ–∑–≤–æ–ª—è–µ—Ç –≤–∞–º –∑–∞–¥–∞–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã –∫ –≤–∞—à–∏–º —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–º PDF-–¥–æ–∫—É–º–µ–Ω—Ç–∞–º.
**–ö–∞–∫ —ç—Ç–æ —Ä–∞–±–æ—Ç–∞–µ—Ç:**
1.  **–í–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenRouter API –∫–ª—é—á** –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.
2.  **–ó–∞–≥—Ä—É–∑–∏—Ç–µ –æ–¥–∏–Ω –∏–ª–∏ –Ω–µ—Å–∫–æ–ª—å–∫–æ PDF-—Ñ–∞–π–ª–æ–≤**.
3.  –ù–∞–∂–º–∏—Ç–µ –∫–Ω–æ–ø–∫—É **"–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã"**, —á—Ç–æ–±—ã —Å–æ–∑–¥–∞—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π.
4.  **–ó–∞–¥–∞–π—Ç–µ —Å–≤–æ–π –≤–æ–ø—Ä–æ—Å** –∏ –ø–æ–ª—É—á–∏—Ç–µ –æ—Ç–≤–µ—Ç, –æ—Å–Ω–æ–≤–∞–Ω–Ω—ã–π –Ω–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–∏ –≤–∞—à–∏—Ö —Ñ–∞–π–ª–æ–≤.
""")

# --- –ë–æ–∫–æ–≤–∞—è –ø–∞–Ω–µ–ª—å ---
with st.sidebar:
    st.header("–ù–∞—Å—Ç—Ä–æ–π–∫–∏")
    # –ö–æ–¥ –¥–ª—è API-–∫–ª—é—á–∞ –æ—Å—Ç–∞–µ—Ç—Å—è –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π...
    try:
        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å –∫–ª—é—á –∏–∑ .env, –µ—Å–ª–∏ –æ–Ω —Å—É—â–µ—Å—Ç–≤—É–µ—Ç –Ω–∞ —É—Ä–æ–≤–Ω–µ –≤—ã—à–µ
        from rag_core import _load_api_key_from_env
        default_key = _load_api_key_from_env()
    except (RuntimeError, ImportError):
        default_key = ""

    api_key_input = st.text_input(
        "OpenRouter API Key",
        type="password",
        placeholder="–í–≤–µ–¥–∏—Ç–µ –≤–∞—à –∫–ª—é—á...",
        value=default_key,
        help="–í—ã –º–æ–∂–µ—Ç–µ –ø–æ–ª—É—á–∏—Ç—å –∫–ª—é—á –Ω–∞ openrouter.ai"
    )
    if api_key_input:
        st.session_state.openrouter_api_key = api_key_input
    
    st.divider()

    uploaded_files = st.file_uploader(
        "–ó–∞–≥—Ä—É–∑–∏—Ç–µ –≤–∞—à–∏ PDF-—Ñ–∞–π–ª—ã",
        type="pdf",
        accept_multiple_files=True
    )
    process_button = st.button("–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã", type="primary")
    st.divider()
    lang_filter_flag = st.checkbox("Language filter ON", value=True, help="–í–∫–ª—é—á–∏—Ç—å –ø—Ä–∏–æ—Ä–∏—Ç–∏–∑–∞—Ü–∏—é –∫–∞–Ω–¥–∏–¥–∞—Ç–æ–≤ –ø–æ —è–∑—ã–∫—É (SAME_LANG_RATIO)")

    # –ü–µ—Ä–µ–∫–ª—é—á–∞—Ç–µ–ª—å Recall level: –ø–µ—Ä–µ–æ–ø—Ä–µ–¥–µ–ª—è–µ–º –±–∞–∑–æ–≤—ã–π efSearch –Ω–∞ —Å–µ—Å—Å–∏—é
    recall_options = {
        "Fast (ef=64)": 64,
        "Balanced (ef=128)": 128,
        "High (ef=256)": 256,
        "Max (ef=384)": 384,
    }
    recall_labels = list(recall_options.keys())
    default_recall_label = st.session_state.get("recall_label", "Balanced (ef=128)")
    try:
        default_idx = recall_labels.index(default_recall_label)
    except ValueError:
        default_idx = 1
    recall_label = st.selectbox("Recall level", recall_labels, index=default_idx, help="–ö–æ–Ω—Ç—Ä–æ–ª—å —Å–∫–æ—Ä–æ—Å—Ç–∏/—Ç–æ—á–Ω–æ—Å—Ç–∏: –±–∞–∑–æ–≤—ã–π efSearch –¥–ª—è HNSW")
    st.session_state.recall_label = recall_label
    rc.HNSW_EF_SEARCH_BASE = int(recall_options.get(recall_label, 128))

# --- –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ ---
# –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –ø—Ä–æ–µ–∫—Ç–∞ (–∫–æ—Ä–µ–Ω—å), –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç —Ç–µ–∫—É—â–µ–π —Ä–∞–±–æ—á–µ–π –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏
BASE_DIR = Path(__file__).resolve().parents[1]
PDF_DIR = BASE_DIR / "pdfs"
VECTOR_STORE_PATH = BASE_DIR / "faiss_index"
PDF_DIR.mkdir(parents=True, exist_ok=True)

# --- –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Å–æ—Å—Ç–æ—è–Ω–∏—è —Å–µ—Å—Å–∏–∏ ---
if "rag_chain" not in st.session_state:
    st.session_state.rag_chain = None
if "messages" not in st.session_state:
    st.session_state.messages = []

# --- –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–Ω–æ–ø–∫–∏ "–û–±—Ä–∞–±–æ—Ç–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã" ---
if process_button:
    if not uploaded_files:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –∑–∞–≥—Ä—É–∑–∏—Ç–µ —Ö–æ—Ç—è –±—ã –æ–¥–∏–Ω PDF-—Ñ–∞–π–ª.")
    elif 'openrouter_api_key' not in st.session_state or not st.session_state.openrouter_api_key:
        st.error("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –≤–∞—à OpenRouter API –∫–ª—é—á –≤ –±–æ–∫–æ–≤–æ–π –ø–∞–Ω–µ–ª–∏.")
    else:
        # –û—á–∏—Å—Ç–∫–∞ —Å—Ç–∞—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤ –∏ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –Ω–æ–≤—ã—Ö
        for file_path in PDF_DIR.iterdir():
            if file_path.is_file():
                file_path.unlink()
        for uploaded_file in uploaded_files:
            with open(PDF_DIR / uploaded_file.name, "wb") as f:
                f.write(uploaded_file.getbuffer())
        
        with st.spinner("–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π... –≠—Ç–æ –º–æ–∂–µ—Ç –∑–∞–Ω—è—Ç—å –≤—Ä–µ–º—è."):
            try:
                build_and_load_knowledge_base(
                    pdf_dir=PDF_DIR,
                    index_dir=VECTOR_STORE_PATH,
                    force_rebuild=True
                )
                st.session_state.rag_chain = create_rag_chain(st.session_state.openrouter_api_key)
                st.session_state.messages = []
                st.success("–ë–∞–∑–∞ –∑–Ω–∞–Ω–∏–π —É—Å–ø–µ—à–Ω–æ —Å–æ–∑–¥–∞–Ω–∞!")
            except Exception as e:
                st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤: {e}")
                if VECTOR_STORE_PATH.exists():
                    shutil.rmtree(VECTOR_STORE_PATH)

# --- –ó–∞–≥—Ä—É–∑–∫–∞ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π –ø—Ä–∏ –ø–µ—Ä–≤–æ–º –∑–∞–ø—É—Å–∫–µ, –µ—Å–ª–∏ –æ–Ω–∞ —É–∂–µ –µ—Å—Ç—å ---
if st.session_state.rag_chain is None and 'openrouter_api_key' in st.session_state:
    try:
        if build_and_load_knowledge_base(
            pdf_dir=PDF_DIR,
            index_dir=VECTOR_STORE_PATH,
            force_rebuild=False
        ):
            st.session_state.rag_chain = create_rag_chain(st.session_state.openrouter_api_key)
            st.toast("‚úÖ –°—É—â–µ—Å—Ç–≤—É—é—â–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π –∑–∞–≥—Ä—É–∂–µ–Ω–∞.", icon="üìö")
    except Exception as e:
        st.warning(f"–ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –±–∞–∑—É –∑–Ω–∞–Ω–∏–π: {e}. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ —Ñ–∞–π–ª—ã –∑–∞–Ω–æ–≤–æ.")

# --- –û—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ —á–∞—Ç–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ ---
st.header("–î–∏–∞–ª–æ–≥")

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])
        if "context" in message and message["context"]:
             with st.expander("–ü–æ–∫–∞–∑–∞—Ç—å –∫–æ–Ω—Ç–µ–∫—Å—Ç, –ø–µ—Ä–µ–¥–∞–Ω–Ω—ã–π –≤ LLM"):
                st.text(message["context"])

if prompt := st.chat_input("–í–∞—à –≤–æ–ø—Ä–æ—Å..."):
    if st.session_state.rag_chain is None:
        st.warning("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —Å–Ω–∞—á–∞–ª–∞ –æ–±—Ä–∞–±–æ—Ç–∞–π—Ç–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –∏–ª–∏ —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ API –∫–ª—é—á –≤–≤–µ–¥–µ–Ω.")
    else:
        st.session_state.messages.append({"role": "user", "content": prompt})
        with st.chat_message("user"):
            st.markdown(prompt)

        with st.chat_message("assistant"):
            with st.spinner("–ò–¥–µ—Ç –≥–∏–±—Ä–∏–¥–Ω—ã–π –ø–æ–∏—Å–∫, RRF –∏ —Ä–µ—Ä–∞–Ω–∫..."):
                try:
                    # –ü—Ä–æ–±—Ä–∞—Å—ã–≤–∞–µ–º —Ñ–ª–∞–≥ –≤ —Ü–µ–ø–æ—á–∫—É —á–µ—Ä–µ–∑ –≥–ª–æ–±–∞–ª—å–Ω—ã–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ (–ø–∞—Ä–∞–º–µ—Ç—Ä —Ñ—É–Ω–∫—Ü–∏–∏)
                    result = hybrid_search_with_rerank(prompt, apply_lang_quota=bool(lang_filter_flag))
                    fused = result.get("fused", [])
                    reranked = result.get("reranked", [])
                    q_lang = result.get("q_lang")
                    active_branches = result.get("active_branches")

                    # –ö—Ä–∞—Ç–∫–∞—è —Å–≤–æ–¥–∫–∞
                    st.markdown(f"**–°–≤–æ–¥–∫–∞:** {{'q_lang': '{q_lang}', 'active_branches': {active_branches}, 'fused': {len(fused)}, 'reranked': {len(reranked)}}}")

                    # –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è —è–∫–æ—Ä—è –¥–ª—è –±—É–¥—É—â–µ–≥–æ –ø—Ä–æ—Å–º–æ—Ç—Ä–∞ PDF
                    def _make_anchor(item: dict) -> str:
                        """–°—Ç—Ä–æ–∏—Ç —è–∫–æ—Ä—å –≤–∏–¥–∞ ?file={source}&page={page} –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏."""
                        src = item.get("source")
                        pg = item.get("page")
                        if src and isinstance(pg, int):
                            return f"?file={src}&page={pg}"
                        return ""

                    # –ë–ª–æ–∫ RRF-—Å–ª–∏—è–Ω–∏–µ (top-20)
                    with st.expander("RRF-—Å–ª–∏—è–Ω–∏–µ (top-20)"):
                        rows_fused = [
                            {
                                "fusion_score": it.get("fusion_score"),
                                "min_rank": it.get("min_rank"),
                                "hits": it.get("hits"),
                                "source": it.get("source"),
                                "page": it.get("page"),
                                "citation": it.get("citation"),
                                "anchor": _make_anchor(it),
                            }
                            for it in fused[:20]
                        ]
                        st.dataframe(rows_fused, use_container_width=True)

                    # –ë–ª–æ–∫ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–µ—Ä–∞–Ω–∫–∞ (top-5)
                    with st.expander("–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ä–µ—Ä–∞–Ω–∫–∞ (top-5)"):
                        rows_rerank = [
                            {
                                "rerank_score": it.get("rerank_score"),
                                "source": it.get("source"),
                                "page": it.get("page"),
                                "citation": it.get("citation"),
                                "retrieval_hits": it.get("hits"),
                                "anchor": _make_anchor(it),
                            }
                            for it in reranked[:5]
                        ]
                        st.dataframe(rows_rerank, use_container_width=True)

                    # –û—Ç–ª–∞–¥–∫–∞ efSearch: –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è (–µ—Å–ª–∏ –≤–∫–ª—é—á–µ–Ω–æ)
                    with st.expander("–î–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∞ efSearch"):
                        st.write(f"–ë–∞–∑–æ–≤—ã–π efSearch (—Å–µ—Å—Å–∏—è): {rc.HNSW_EF_SEARCH_BASE}")
                        st.caption("–ü—Ä–∏–º–µ–Ω—ë–Ω–Ω—ã–π ef –¥–ª—è –∫–∞–∂–¥–æ–π dense-–≤–µ—Ç–∫–∏ –ª–æ–≥–∏—Ä—É–µ—Ç—Å—è –ø—Ä–∏ RAG_DEBUG=1 –≤ —Å–µ—Ä–≤–µ—Ä–Ω—ã–π –ª–æ–≥.")

                    # –ü–æ–∫–∞–∑–∞—Ç—å —è–∑—ã–∫–æ–≤—ã–µ –¥–æ–ª–∏ –ø–æ –≤–µ—Ç–∫–∞–º
                    with st.expander("–Ø–∑—ã–∫–æ–≤—ã–µ –¥–æ–ª–∏ –ø–æ –≤–µ—Ç–∫–∞–º"):
                        if active_branches:
                            from rag_core import chunks_metadata
                            def _share(items, target_lang):
                                if not items:
                                    return (0, 0, 0.0)
                                same = 0
                                for it in items:
                                    cid = it.get("chunk_id")
                                    if isinstance(cid, int) and 0 <= cid < len(chunks_metadata):
                                        if chunks_metadata[cid].get("lang") == target_lang:
                                            same += 1
                                other = len(items) - same
                                ratio = (same / len(items)) if len(items) else 0.0
                                return (same, other, ratio)
                        
                        # –ò—Å–ø–æ–ª—å–∑—É–µ–º reranked –∫–∞–∫ –∫–æ–º–ø–∞–∫—Ç–Ω–æ–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω–∏–µ top-N
                        branch_map = {
                            "dense_en": ('en', [it for it in fused if 'dense_en' in (it.get('hits') or [])]),
                            "bm25_en": ('en', [it for it in fused if 'bm25_en' in (it.get('hits') or [])]),
                            "dense_ru": ('ru', [it for it in fused if 'dense_ru' in (it.get('hits') or [])]),
                            "bm25_ru": ('ru', [it for it in fused if 'bm25_ru' in (it.get('hits') or [])]),
                        }
                        for br in active_branches:
                            target_lang, items = branch_map.get(br, (None, []))
                            if not target_lang:
                                continue
                            same, other, share = _share(items, target_lang)
                            st.write(f"{br}: same_lang={same}, other_lang={other}, share={share:.2f}")

                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"–°–≤–æ–¥–∫–∞: {{'fused': {len(fused)}, 'reranked': {len(reranked)}}}",
                    })
                except Exception as e:
                    st.error(f"–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –ø–æ–∏—Å–∫–µ/—Å–ª–∏—è–Ω–∏–∏/—Ä–µ—Ä–∞–Ω–∫–µ: {e}")